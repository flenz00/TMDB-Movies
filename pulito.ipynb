{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory analysis and prediction on the \"TMDB 5000 Movie Dataset\" dataset**\n",
    "\n",
    "***Authors: Bava Flavio 4836427 , Ciarlo Francesco 4640121, Oldrini Edoardo 4055097***\n",
    "\n",
    "**Abstract**\n",
    "\n",
    "The following data analysis aims to study an approach for the production of a movie.<br><br>\n",
    "This file is divided like so:\n",
    "* Dataset checking and preparation\n",
    "* Initial exploration of the dataset\n",
    "* Proposal predictive models based on previous observations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing libraries and dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "from ast import literal_eval\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import warnings \n",
    "\n",
    "#initial settings\n",
    "warnings.filterwarnings('ignore') \n",
    "pd.set_option('display.max_columns',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies = pd.read_csv('tmdb_5000_movies.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploratory analysis of the dataset**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First of all, we intend to have an overall idea of the available dataset, in particular the dimensions of the dataset and the structure of the entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset has {} rows and {} columns\".format(Movies.shape[0],Movies.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns like homepage, spoken_languages and title are usless or redondant, hence we proceed to drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies.drop(['homepage','spoken_languages','title'],inplace=True,axis='columns')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We check if the types of datas are coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vediamo i tipi dei vari attributi\n",
    "Movies.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data tyoes are coherent with the information they represent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We check if any null values are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vediamo dati mancanti\n",
    "Movies.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column tagline has a huge number of null values, we will manage them when we'll work on this feature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some columns are in Json format, hence we proceed to convert them to lists"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of auxiliary funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(x):\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        return names\n",
    "    return []\n",
    "\n",
    "def get_ISO(x):\n",
    "    if isinstance(x, list):\n",
    "        isos = [i['iso_3166_1'] for i in x]\n",
    "        return isos\n",
    "    return []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_to_manage = ['genres','keywords','production_countries','production_companies']\n",
    "for f in feat_to_manage:\n",
    "    Movies[f] = Movies[f].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn genres into list\n",
    "Movies['genres'] = Movies['genres'].apply(get_name)\n",
    "#Turn prod_countries into list\n",
    "Movies['production_countries'] = Movies['production_countries'].apply(get_ISO)\n",
    "#Turn prod_companies into list\n",
    "Movies['production_companies'] = Movies['production_companies'].apply(get_name)\n",
    "#Turn keywords into list\n",
    "Movies['keywords'] = Movies['keywords'].apply(get_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some movies are in post producion or are still just rumored but we want to work only on released movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies = Movies.query('status == \"Released\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset Analysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Budget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's have a first look to the budget feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies['budget'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum value of the budget feature is 0. We must discard movies with a non acceptable budget, hence we keep only movie budgets with greater than 10 k, any value < 10 k is interpreted as wrong hence put o nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in Movies.index:\n",
    "    if Movies.loc[row,'budget'] < 10000:\n",
    "        Movies.loc[row,'budget'] = np.nan\n",
    "        \n",
    "Movies['budget'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now the budget are acceotable, we divide movies in three classes by budget:\n",
    "- Low: 1.000000e+04 <= x <= 8.975000e+06 (class 1) \n",
    "- Medium: 8.975000e+06 < x <= 5.000000e+07 (class 2)\n",
    "- High: 5.000000e+07 < x <= 3.800000e+08 (class 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1.000000e+04, 8.975000e+06, 5.000000e+07, 3.800000e+08]\n",
    "labels=[1,2,3]\n",
    "Movies['budget_class'] = pd.cut(Movies['budget'],bins=bins,labels=labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's print the count of movies for each budget class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = Movies['budget_class'].value_counts().sort_values(ascending=True).plot(kind='bar')\n",
    "ax.set_xlabel(\"Budget Class\")\n",
    "ax.set_ylabel(\"Quantity\")\n",
    "plt.xticks(rotation=\"horizontal\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is coherent with the divions we made"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's check the distribution of budgets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.distplot(Movies['budget'])\n",
    "sns.set(rc={'figure.figsize':(15,6)})\n",
    "plt.suptitle('Budget distribution')\n",
    "plt.show()\n",
    "\n",
    "print(\"Budget skewness: \",Movies['budget'].skew())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is skewed, this could be a problem for the machine learning algorithm, hance we try to adjust the skewness of the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(12,6))\n",
    "Movies['log_budget'] = np.log1p(Movies['budget'])\n",
    "sns.distplot(Movies['budget'],ax=ax1)\n",
    "sns.distplot(Movies['log_budget'],ax=ax2)\n",
    "fig.suptitle(\"Comparison between budget and log_budget\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness before log : {} and Skewness after log : {}\".format(Movies['budget'].skew(),Movies['log_budget'].skew()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revenues ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Movies with 0$ revenues: ',Movies[Movies['revenue'] == 0].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mettiamo anche questi a Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in Movies.index:\n",
    "    if (Movies.loc[row, 'revenue'] == 0):\n",
    "        Movies.loc[row, 'revenue'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies['revenue'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies['log_revenue'] = np.log1p(Movies['revenue'])\n",
    "fig , (ax1,ax2) = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "sns.distplot(Movies['revenue'],ax=ax1)\n",
    "sns.distplot(Movies['log_revenue'],ax=ax2)\n",
    "fig.suptitle(\"Comparison between revenue and log_revenue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness before log : {} and Skewness after log : {}\".format(Movies['revenue'].skew(),Movies['log_revenue'].skew()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vogliamo eliminare quei film che hanno una percentuale di vote_count(voti dati) bassa,perché andrebbe a creare degli squilibri,\n",
    "visto che un film votato 8,però da 5 persone,non é affidabile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: potremmo anche fare questo lavoro sul dataset di partenza aggiungendo una colonna, metà avranno nan\n",
    "C = Movies['vote_average'].mean()\n",
    "C\n",
    "m = Movies['vote_count'].quantile(0.5)\n",
    "\n",
    "for i in Movies.index:\n",
    "    if Movies.loc[i,'vote_count'] <= m:\n",
    "        Movies.loc[i,'vote_count'] = np.nan\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "q_movies = Movies[['id','vote_count','vote_average']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riteniamo importante che la media dei voti sia pesata con il numero di voti che la generano, per fare questo usiamo la formula consigliata dal sito IMBD e togliamo le due colonne vote_average e vote_count per unirle in una che le metta insieme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rating pesato\n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = x['vote_count']\n",
    "    R = x['vote_average']\n",
    "    # Calculation based on the IMDB formula\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new feature 'score' and calculate its value with `weighted_rating()`\n",
    "q_movies['score'] = q_movies.apply(weighted_rating, axis=1)\n",
    "\n",
    "q_movies.drop(['vote_average','vote_count'],inplace=True,axis='columns')\n",
    "\n",
    "#Merge dei dataframe,ora Movies ha anche la colonna Score\",\n",
    "Movies = pd.merge(Movies,q_movies,on='id',how='inner')\n",
    "\n",
    "Movies.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo eliminato dei film (in q_movies), quelli con troppi pochi voti per poter essere presi in considerazione per quanto riguarda il voto ricevuto e abbiamo poi riunito i due dataframe,cosi ora Movies ha anche la colonna score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profitti ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misuriamo i ricavi rispetto al budget tramite una funzione,e aggiungiamo una nuova colonna chiamata 'profit_perc' contente i risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_profit_perc(x):\n",
    "    if (x.revenue>0) and (x.budget>0):\n",
    "        return ((x.revenue-x.budget)/x.budget)*100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies = Movies.assign(profit_perc = lambda x: x.budget)\n",
    "for row in Movies.index:\n",
    "    Movies.loc[row,'profit_perc'] =  calculate_profit_perc(Movies.loc[row])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo funzione che dato un genere calcola la media dei profitti dei film che lo contengono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Movies\n",
    "temp.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quanti film ci sono per genere con profitto diverso da Nan\n",
    "def films_per_genres(genre):\n",
    "    count = 0\n",
    "    for row in temp.index:\n",
    "        if (genre in temp.loc[row, 'genres'] and (temp.loc[row,'profit_perc'] != np.nan)):\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "#Profitto per genere\n",
    "def genre_average_profits(genre):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for row in temp.index:\n",
    "        if (genre in temp.loc[row, 'genres'] and (temp.loc[row,'profit_perc'] != np.nan)):\n",
    "            sum += temp.loc[row, 'profit_perc']\n",
    "            count+=1\n",
    "    return sum/count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres=[]\n",
    "for row in temp.index:\n",
    "    _gen = temp.loc[row,'genres']\n",
    "    for g in _gen:\n",
    "        if g not in genres:\n",
    "            genres.append(g)\n",
    "\n",
    "profits=[]\n",
    "for g in genres:\n",
    "    profits.append(genre_average_profits(g))\n",
    "            \n",
    "print(\"Profitto associato ad ogni genere:\")\n",
    "for i in range(0,len(genres)):\n",
    "    print('\\t',genres[i], \" has a mean profit of \", profits[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo osservare come alcuni film abbiano un profitto molto alto,questo é dato dal fatto che ad esempio i film Horror hanno guadagnato molto e ve ne sono pochi all'interno del dataset,vediamo quindi le cardinalità di ogni genere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films = []\n",
    "for el in genres:\n",
    "    films.append(films_per_genres(el))\n",
    "    \n",
    "print(\"I generi presenti nel dataframe sono:\")\n",
    "for genre,film in zip(genres,films):\n",
    "    print(genre,film)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I Documentari ad esempio sono molti pochi rispetto al totale dei film ed hanno un profitto percentuale pari a 6119 circa ,quindi per il motivo citato in precedenza sbilanciano di molto i conti. Possiamo permetterci di escluderli,visto che sono solamente 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres.remove(genres[-1])\n",
    "profits.remove(profits[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(genres,profits)\n",
    "fig.set_figwidth(27)\n",
    "fig.set_figheight(13)\n",
    "plt.xticks(rotation=45,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Genres\", fontsize=20)\n",
    "plt.ylabel(\"Profits\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_profit = np.log1p(profits)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(genres,log_profit)\n",
    "fig.set_figwidth(27)\n",
    "fig.set_figheight(13)\n",
    "plt.xticks(rotation=45,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Genres\", fontsize=20)\n",
    "plt.ylabel(\"Log Profits\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo quali sono le parole più frequenti presenti tra le keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from wordcloud import WordCloud, STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(12,12))\n",
    "stop_words=set(stopwords.words('english'))\n",
    "stop_words.update(',',';','!','?','.','(',')','$','#','+',':','...',' ','')\n",
    "\n",
    "Movies['keywords'].dropna(inplace=True)\n",
    "Movies['keywords'] = Movies['keywords'].astype(str)\n",
    "words=Movies['keywords'].apply(nltk.word_tokenize)\n",
    "word=[]\n",
    "for i in words:\n",
    "    word.extend(i)\n",
    "word=pd.Series(word)\n",
    "word=([i for i in word.str.lower() if i not in stop_words])\n",
    "wc = WordCloud(background_color=\"black\", max_words=2000,stopwords=STOPWORDS, max_font_size= 60,width=1000,height=600)\n",
    "wc.generate(\" \".join(word))\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(10,10)\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Date ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertiamo le release date in formato datetime\n",
    "temp['release_date'] = pd.to_datetime(temp['release_date'])\n",
    "temp['release_year'] = temp['release_date'].dt.year\n",
    "temp['release_month'] = temp['release_date'].dt.month\n",
    "temp['release_day'] = temp['release_date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['decades'] = temp['release_date'].apply(lambda x : (x.year // 10)*10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantità di film rilasciati nei diversi mesi dell' anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "sns.countplot(x='release_month',data=temp)\n",
    "plt.suptitle(\"Films released every month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "sns.countplot(x='release_day',data=temp)\n",
    "plt.suptitle(\"Films released every day\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"release_date\",y=\"revenue\",data=temp,hue=\"budget_class\")\n",
    "sns.set(rc = {'figure.figsize':(6,6)})\n",
    "ax.set_title(\"Revenue durante gli anni\")\n",
    "ax.set_xlabel(\"Release Year\")\n",
    "ax.set_ylabel(\"Revenue\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il grafico sopra mostra come le revenues siano aumentate nel tempo,cosi come i budget investiti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = temp.groupby(['release_month'])['revenue'].mean()\n",
    "data = [go.Scatter(x=d2.index, y=d2.values, name='mean revenue', yaxis='y')]\n",
    "layout = go.Layout(dict(title = \"Average revenue per month\",\n",
    "                  xaxis = dict(title = 'Month'),\n",
    "                  yaxis2=dict(title='Average revenue', overlaying='y', side='right')\n",
    "                  ),legend=dict(\n",
    "                orientation=\"v\"))\n",
    "py.iplot(dict(data=data, layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = temp.groupby(['release_day'])['revenue'].mean()\n",
    "data = [go.Scatter(x=d2.index, y=d2.values, name='mean revenue', yaxis='y')]\n",
    "layout = go.Layout(dict(title = \"Average revenue per Day\",\n",
    "                  xaxis = dict(title = 'Day'),\n",
    "                  yaxis2=dict(title='Average revenue', overlaying='y', side='right')\n",
    "                  ),legend=dict(\n",
    "                orientation=\"v\"))\n",
    "py.iplot(dict(data=data, layout=layout))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['log_popularity'] = np.log(temp['popularity'])\n",
    "\n",
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "sns.distplot(temp['popularity'],ax=ax1)\n",
    "sns.distplot(temp['log_popularity'],ax=ax2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness before log : {} and Skewness after log : {}\".format(temp['popularity'].skew(),temp['log_popularity'].skew()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(12,6)})\n",
    "ax = sns.scatterplot(x='popularity',y='revenue',data=temp,hue=\"budget_class\")\n",
    "ax.set_title(\"Popularity and revenues organized on budget_class\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cast e Direttori #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast = pd.read_csv(\"tmdb_5000_credits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_to_manage = ['cast','crew']\n",
    "for f in feat_to_manage:\n",
    "    cast[f] = cast[f].apply(literal_eval)\n",
    "\n",
    "#Two functions that convert directors and actors from json to list-str\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "\n",
    "def get_actors(x): #TODO:si può usare senza fare modifiche get_name?\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        \n",
    "        return names\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two new column correctly formatted\n",
    "cast['director'] = cast['crew'].apply(get_director)\n",
    "cast['actors'] = cast['cast'].apply(get_actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop old columns\n",
    "cast.drop('cast',inplace=True,axis=1)\n",
    "cast.drop('crew',inplace=True,axis=1)\n",
    "cast.drop('title',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename Movie_id to id, preparing for the merge\n",
    "cast = cast.rename(columns={'movie_id': 'id'})\n",
    "\n",
    "#Merge two dataframe Movies,cast\n",
    "full_df = pd.merge(temp,cast,on=\"id\",how=\"inner\")\n",
    "recommend_df = full_df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attori ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors=[]\n",
    "\n",
    "\n",
    "for i in full_df['actors']:\n",
    "    actors.extend(i)\n",
    "\n",
    "actors = list(filter(None, actors))\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(12,10))\n",
    "ax=pd.Series(actors).value_counts()[:15].sort_values(ascending=True).plot.barh(width=0.9,color=sns.color_palette('inferno_r',40))\n",
    "for i, v in enumerate(pd.Series(actors).value_counts()[:15].sort_values(ascending=True).values): \n",
    "    ax.text(.8, i, v,fontsize=10,color='black',weight='bold')\n",
    "\n",
    "plt.title('Actors with highest appearance')\n",
    "ax.patches[14].set_facecolor('r')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registi ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors=[]\n",
    "\n",
    "\n",
    "for i in full_df['director']:\n",
    "    directors.append(i)\n",
    "\n",
    "directors = list(filter(None, directors))\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(12,10))\n",
    "ax=pd.Series(directors).value_counts()[:14].sort_values(ascending=True).plot.barh(width=0.9,color=sns.color_palette('inferno_r',40))\n",
    "for i, v in enumerate(pd.Series(directors).value_counts()[:14].sort_values(ascending=True).values): \n",
    "    ax.text(.8, i, v,fontsize=10,color='black',weight='bold')\n",
    "\n",
    "plt.title('Directors with highest appearance')\n",
    "ax.patches[13].set_facecolor('r')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo Score medio per i registi più presenti(>= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the directors with made films >= 10,then calculate the mean scores\n",
    "#Dovrebbe fare lo stesso lavoro di score_for_director applicato poi alla hashmap, quindi ho rimosso entrambe\n",
    "\n",
    "director_group = full_df.groupby('director').filter(lambda x : len(x) >= 10)\n",
    "mean_scores = director_group.groupby('director')['score'].mean().sort_values(ascending=False).reset_index(name=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(mean_scores['director'],mean_scores['score'],color='navy')\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(13)\n",
    "plt.xticks(rotation=45,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Directors\", fontsize=20)\n",
    "plt.ylabel(\"Scores\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predizioni #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revenue ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "supertest = temp.copy()\n",
    "def prepare(temp):\n",
    "    temp['_budget_runtime_ratio'] = temp['budget']/temp['runtime'] \n",
    "    temp['_budget_popularity_ratio'] = temp['budget']/temp['popularity']\n",
    "    temp['_budget_year_ratio'] = temp['budget']/(temp['release_year']*temp['release_year'])\n",
    "    temp['_releaseYear_popularity_ratio'] = temp['release_year']/temp['popularity']\n",
    "    temp['_releaseYear_popularity_ratio2'] = temp['popularity']/temp['release_year']\n",
    "    temp['_year_to_log_budget'] = temp['release_year'] / temp['log_budget']\n",
    "    temp['_year_to_log_popularity'] = temp['release_year'] / temp['log_popularity']\n",
    "\n",
    "    ##temp['has_homepage'] = 0\n",
    "    ##temp.loc[pd.isnull(temp['homepage']) ,\"has_homepage\"] = 1\n",
    "    \n",
    "    ##temp['isTaglineNA'] = 0\n",
    "    ##temp.loc[temp['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n",
    "    \n",
    "    ##temp['isTitleDifferent'] = 1\n",
    "    ##temp.loc[ temp['original_title'] == temp['title'] ,\"isTitleDifferent\"] = 0\n",
    "    ##temp['isMovieReleased'] = 1\n",
    "    ##temp.loc[ temp['status'] != \"Released\" ,\"isMovieReleased\"] = 0 \n",
    "\n",
    "    temp['original_title_letter_count'] = temp['original_title'].str.len() \n",
    "    temp['original_title_word_count'] = temp['original_title'].str.split().str.len() \n",
    "    #temp['title_word_count'] = temp['title'].str.split().str.len()\n",
    "    temp['overview_word_count'] = temp['overview'].str.split().str.len()\n",
    "    temp['tagline_word_count'] = temp['tagline'].str.split().str.len()\n",
    "    #temp['meanruntimeByYear'] = temp.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\n",
    "    #temp['meanPopularityByYear'] = temp.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\n",
    "    #temp['meanBudgetByYear'] = temp.groupby(\"release_year\")[\"budget\"].aggregate('mean')\n",
    "\n",
    "    return temp\n",
    "new_temp= prepare(supertest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>budget_class</th>\n",
       "      <th>log_budget</th>\n",
       "      <th>log_revenue</th>\n",
       "      <th>score</th>\n",
       "      <th>profit_perc</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_month</th>\n",
       "      <th>release_day</th>\n",
       "      <th>decades</th>\n",
       "      <th>log_popularity</th>\n",
       "      <th>_budget_runtime_ratio</th>\n",
       "      <th>_budget_popularity_ratio</th>\n",
       "      <th>_budget_year_ratio</th>\n",
       "      <th>_releaseYear_popularity_ratio</th>\n",
       "      <th>_releaseYear_popularity_ratio2</th>\n",
       "      <th>_year_to_log_budget</th>\n",
       "      <th>_year_to_log_popularity</th>\n",
       "      <th>original_title_letter_count</th>\n",
       "      <th>original_title_word_count</th>\n",
       "      <th>overview_word_count</th>\n",
       "      <th>tagline_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000.0</td>\n",
       "      <td>[Action, Adventure, Fantasy, Science Fiction]</td>\n",
       "      <td>19995</td>\n",
       "      <td>[culture clash, future, space war, space colon...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[Ingenious Film Partners, Twentieth Century Fo...</td>\n",
       "      <td>[US, GB]</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2.787965e+09</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>3</td>\n",
       "      <td>19.283571</td>\n",
       "      <td>21.748578</td>\n",
       "      <td>7.1783</td>\n",
       "      <td>1076.356577</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.013548</td>\n",
       "      <td>1.462963e+06</td>\n",
       "      <td>1.575404e+06</td>\n",
       "      <td>58.720328</td>\n",
       "      <td>13.354376</td>\n",
       "      <td>0.074882</td>\n",
       "      <td>104.18195</td>\n",
       "      <td>400.714207</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        budget                                         genres     id  \\\n",
       "0  237000000.0  [Action, Adventure, Fantasy, Science Fiction]  19995   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [culture clash, future, space war, space colon...                en   \n",
       "\n",
       "  original_title                                           overview  \\\n",
       "0         Avatar  In the 22nd century, a paraplegic Marine is di...   \n",
       "\n",
       "   popularity                               production_companies  \\\n",
       "0  150.437577  [Ingenious Film Partners, Twentieth Century Fo...   \n",
       "\n",
       "  production_countries release_date       revenue  runtime    status  \\\n",
       "0             [US, GB]   2009-12-10  2.787965e+09    162.0  Released   \n",
       "\n",
       "                       tagline  vote_average  vote_count budget_class  \\\n",
       "0  Enter the World of Pandora.           7.2     11800.0            3   \n",
       "\n",
       "   log_budget  log_revenue   score  profit_perc  release_year  release_month  \\\n",
       "0   19.283571    21.748578  7.1783  1076.356577          2009             12   \n",
       "\n",
       "   release_day  decades  log_popularity  _budget_runtime_ratio  \\\n",
       "0            3     2000        5.013548           1.462963e+06   \n",
       "\n",
       "   _budget_popularity_ratio  _budget_year_ratio  \\\n",
       "0              1.575404e+06           58.720328   \n",
       "\n",
       "   _releaseYear_popularity_ratio  _releaseYear_popularity_ratio2  \\\n",
       "0                      13.354376                        0.074882   \n",
       "\n",
       "   _year_to_log_budget  _year_to_log_popularity  original_title_letter_count  \\\n",
       "0            104.18195               400.714207                            6   \n",
       "\n",
       "   original_title_word_count  overview_word_count  tagline_word_count  \n",
       "0                          1                   28                   5  "
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" new_temp['genres'] = new_temp['genres'].apply(lambda x : x[0] if len(x) > 0 else None)\n",
    "new_temp['keywords'] = new_temp['keywords'].apply(lambda x : x[0] if len(x) > 0 else None)\n",
    "new_temp['production_countries'] = new_temp['production_countries'].apply(lambda x : x[0] if len(x) > 0 else None)\n",
    "new_temp['production_companies'] = new_temp['production_companies'].apply(lambda x : x[0] if len(x) > 0 else None) \"\"\"\n",
    "new_temp.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def format_prod_count(list):\n",
    "    for el in list:\n",
    "        re.sub('[^A-Za-z0-9_]+', '', str(el))\n",
    "\n",
    "new_temp['production_companies'] = new_temp['production_companies'].apply(lambda x:format_prod_count(x))\n",
    "new_temp['production_companies'] = new_temp['production_companies'].apply(lambda x:[re.sub('[^A-Za-z0-9_]+', '', str(el))] for el in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genres\n",
    "df=pd.DataFrame( {'genres': new_temp['genres']})\n",
    "df= pd.get_dummies(df.genres.apply(pd.Series).stack()).sum(level=0)\n",
    "new_temp = pd.concat([new_temp,df],axis = 1)\n",
    "\n",
    "#keywords\n",
    "df=pd.DataFrame( {'keywords': new_temp['keywords']})\n",
    "df= pd.get_dummies(df.keywords.apply(pd.Series).stack()).sum(level=0)\n",
    "new_temp = pd.concat([new_temp,df],axis = 1)\n",
    "\n",
    "#production companies\n",
    "df=pd.DataFrame( {'production_companies': new_temp['production_companies']})\n",
    "df= pd.get_dummies(df.production_companies.apply(pd.Series).stack()).sum(level=0)\n",
    "new_temp = pd.concat([new_temp,df],axis = 1)\n",
    "\n",
    "#production countries\n",
    "df=pd.DataFrame( {'production_countries': new_temp['production_countries']})\n",
    "df= pd.get_dummies(df.production_countries.apply(pd.Series).stack()).sum(level=0)\n",
    "new_temp = pd.concat([new_temp,df],axis = 1)\n",
    "\n",
    "\n",
    "new_temp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_temp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns=['status','release_date','tagline', 'overview', 'original_title','original_language','id','revenue','profit_perc','genres', 'keywords','production_companies','production_countries']\n",
    "new_temp= new_temp.drop(drop_columns, axis=1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formating for modeling\n",
    "y = new_temp['log_revenue']\n",
    "X = new_temp.drop(['log_revenue'], axis=1)\n",
    "#y = np.log1p(new_temp['revenue']) proviamo senza\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 30,\n",
    "         'min_data_in_leaf': 20,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': 5,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'mae',\n",
    "         \"lambda_l1\": 0.2,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(**params, n_estimators = 10000, nthread = 4, n_jobs = -1)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgb_model.predict(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "r2 = r2_score(y_valid,y_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Real Values': y_valid, 'Predicted Values': y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_valid, y_pred)\n",
    "tmp = [min(np.concatenate((y_train,y_valid))),\n",
    "       max(np.concatenate((y_train,y_valid)))]\n",
    "plt.plot(tmp,tmp,'r')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertiamo tutte le feature categoriche in binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(genre_list):\n",
    "    binaryList = []\n",
    "    \n",
    "    for genre in genres:\n",
    "        if genre in genre_list:\n",
    "            binaryList.append(1)\n",
    "        else:\n",
    "            binaryList.append(0)\n",
    "    \n",
    "    return binaryList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['genres_bin'] = full_df['genres'].apply(lambda x: binary(x))\n",
    "full_df['genres_bin'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip(full_df['actors'],full_df.index):\n",
    "    list2=[]\n",
    "    list2=i[:4]\n",
    "    full_df.loc[j,'actors']=str(list2)\n",
    "full_df['actors']=full_df['actors'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n",
    "full_df['actors']=full_df['actors'].str.split(',')\n",
    "for i,j in zip(full_df['actors'],full_df.index):\n",
    "    list2=[]\n",
    "    list2=i\n",
    "    list2.sort()\n",
    "    full_df.loc[j,'actors']=str(list2)\n",
    "full_df['actors']=full_df['actors'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n",
    "full_df['actors']=full_df['actors'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['actors'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_list=[]\n",
    "for row in full_df.index:\n",
    "    _actors = full_df.loc[row,'actors']\n",
    "    for g in _actors:\n",
    "        if g not in actor_list:\n",
    "            actor_list.append(g)\n",
    "\n",
    "\n",
    "def binary(cast_list):\n",
    "    binaryList = []\n",
    "    \n",
    "    for genre in actor_list:\n",
    "        if genre in cast_list:\n",
    "            binaryList.append(1)\n",
    "        else:\n",
    "            binaryList.append(0)\n",
    "    \n",
    "    return binaryList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['actors_bin'] = full_df['actors'].apply(lambda x: binary(x))\n",
    "full_df['actors_bin'].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip(full_df['director'],full_df.index):\n",
    "    list2=[]\n",
    "    list2=i[:4]\n",
    "    full_df.loc[j,'director']=str(list2)\n",
    "full_df['director']=full_df['director'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n",
    "full_df['director']=full_df['director'].str.split(',')\n",
    "for i,j in zip(full_df['director'],full_df.index):\n",
    "    list2=[]\n",
    "    list2=i\n",
    "    list2.sort()\n",
    "    full_df.loc[j,'director']=str(list2)\n",
    "full_df['director']=full_df['director'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n",
    "full_df['director']=full_df['director'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_list=[]\n",
    "for row in full_df.index:\n",
    "    _actors = full_df.loc[row,'director']\n",
    "    for g in _actors:\n",
    "        if g not in director_list:\n",
    "            director_list.append(g)\n",
    "\n",
    "def binary(directors):\n",
    "    binaryList = []\n",
    "    \n",
    "    for direct in director_list:\n",
    "        if direct in directors:\n",
    "            binaryList.append(1)\n",
    "        else:\n",
    "            binaryList.append(0)\n",
    "    \n",
    "    return binaryList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['director_bin'] = full_df['director'].apply(lambda x: binary(x))\n",
    "full_df['director_bin'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['keywords']=full_df['keywords'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'').str.replace('\"','')\n",
    "full_df['keywords']=full_df['keywords'].str.split(',')\n",
    "for i,j in zip(full_df['keywords'],full_df.index):\n",
    "    list2=[]\n",
    "    list2=i[:4]\n",
    "    full_df.loc[j,'keywords']=str(list2)\n",
    "full_df['keywords']=full_df['keywords'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n",
    "full_df['keywords']=full_df['keywords'].str.split(',')\n",
    "for i,j in zip(full_df['keywords'],full_df.index):\n",
    "    list2=[]\n",
    "    list2=i\n",
    "    list2.sort()\n",
    "    full_df.loc[j,'keywords']=str(list2)\n",
    "full_df['keywords']=full_df['keywords'].str.strip('[]').str.replace(' ','').str.replace(\"'\",'')\n",
    "full_df['keywords']=full_df['keywords'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = []\n",
    "for index, row in full_df.iterrows():\n",
    "    genres = row[\"keywords\"]\n",
    "    \n",
    "    for genre in genres:\n",
    "        if genre not in words_list:\n",
    "            words_list.append(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(words):\n",
    "    binaryList = []\n",
    "    \n",
    "    for genre in words_list:\n",
    "        if genre in words:\n",
    "            binaryList.append(1)\n",
    "        else:\n",
    "            binaryList.append(0)\n",
    "    \n",
    "    return binaryList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['words_bin'] = full_df['keywords'].apply(lambda x: binary(x))\n",
    "full_df['words_bin'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df[(full_df['vote_average']!=0)] #removing the movies with 0 score and without drector names \n",
    "full_df = full_df[full_df['director']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id = list(range(0,full_df.shape[0]))\n",
    "full_df['new_id']=new_id\n",
    "full_df=full_df[['original_title','genres','vote_average','genres_bin','actors_bin','new_id','director','director_bin','words_bin']]\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def Similarity(movieId1, movieId2):\n",
    "    a = full_df.iloc[movieId1]\n",
    "    b = full_df.iloc[movieId2]\n",
    "    \n",
    "    genresA = a['genres_bin']\n",
    "    genresB = b['genres_bin']\n",
    "    \n",
    "    genreDistance = spatial.distance.cosine(genresA, genresB)\n",
    "    \n",
    "    scoreA = a['actors_bin']\n",
    "    scoreB = b['actors_bin']\n",
    "    scoreDistance = spatial.distance.cosine(scoreA, scoreB)\n",
    "    \n",
    "    directA = a['director_bin']\n",
    "    directB = b['director_bin']\n",
    "    directDistance = spatial.distance.cosine(directA, directB)\n",
    "    \n",
    "    wordsA = a['words_bin']\n",
    "    wordsB = b['words_bin']\n",
    "    wordsDistance = spatial.distance.cosine(directA, directB)\n",
    "    return genreDistance + directDistance + scoreDistance + wordsDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Similarity(3,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def whats_my_score(name):\n",
    "    new_movie=full_df[full_df['original_title'].str.contains(name)].iloc[0].to_frame().T\n",
    "    print('Selected Movie: ',new_movie.original_title.values[0],'\\n')\n",
    "    def getNeighbors(baseMovie, K):\n",
    "        distances = []\n",
    "    \n",
    "        for index, movie in full_df.iterrows():\n",
    "            if movie['new_id'] != baseMovie['new_id'].values[0]:\n",
    "                dist = Similarity(baseMovie['new_id'].values[0], movie['new_id'])\n",
    "                distances.append((movie['new_id'], dist))\n",
    "    \n",
    "        distances.sort(key=operator.itemgetter(1))\n",
    "        neighbors = []\n",
    "    \n",
    "        for x in range(K):\n",
    "            neighbors.append(distances[x])\n",
    "        return neighbors\n",
    "\n",
    "    K = 10\n",
    "    avgRating = 0\n",
    "    neighbors = getNeighbors(new_movie, K)\n",
    "\n",
    "    \n",
    "    for neighbor in neighbors:\n",
    "        avgRating = avgRating+full_df.iloc[neighbor[0]][2]  \n",
    "    \n",
    "    #print('\\n')\n",
    "    avgRating = avgRating/K\n",
    "    print('The predicted rating for %s is: %f' %(new_movie['original_title'].values[0],avgRating))\n",
    "    predicted = (new_movie['original_title'].values[0],avgRating)\n",
    "    print('The actual rating for %s is %f' %(new_movie['original_title'].values[0],new_movie['vote_average']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whats_my_score('Avatar')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consigliati (Overview,Title) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "recommend_df['overview'] = recommend_df['overview'].fillna('')\n",
    "tfidf_matr = tfidf.fit_transform(recommend_df['overview'])\n",
    "print(tfidf_matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_similarity = linear_kernel(tfidf_matr,tfidf_matr)\n",
    "cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(recommend_df.index, index=recommend_df['original_title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommendation using cosine similarity\n",
    "def get_recommendations(title, cosine_similarity=cosine_similarity):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwise similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_similarity[idx]))\n",
    "    #print(sim_scores)\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    #print(sim_scores)\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return recommend_df['original_title'].iloc[movie_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations('The Avengers')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consigliati (Keywords,Actors,Directors,Genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        #Check if director exists. If not, return empty string\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply clean_data function to your features.\n",
    "features = ['actors', 'keywords', 'director', 'genres']\n",
    "\n",
    "\n",
    "for feature in features:\n",
    "    recommend_df[feature] = recommend_df[feature].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(x):\n",
    "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['actors']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n",
    "recommend_df['soup'] = recommend_df.apply(create_soup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(recommend_df['soup'])\n",
    "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)\n",
    "# Reset index of our main DataFrame and construct reverse mapping as before\n",
    "recommend_df = recommend_df.reset_index()\n",
    "indices = pd.Series(recommend_df.index, index=recommend_df['original_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_recommendations(\"The Godfather\", cosine_sim2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referenze\n",
    "#LgbRegressor https://www.kaggle.com/code/somang1418/eda-lgb-xgb-modelings-with-a-cute-panda-meme <br>\n",
    "#Recommendation 1-2 https://www.kaggle.com/code/ibtesama/getting-started-with-a-movie-recommendation-system <br>\n",
    "#Score https://www.kaggle.com/code/ash316/what-s-my-score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
