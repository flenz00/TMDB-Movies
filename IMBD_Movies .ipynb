{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exploratory analysis and prediction on the \"TMDB 5000 Movie Dataset\" dataset**\n",
    "\n",
    "***Authors: Bava Flavio 4836427 , Ciarlo Francesco 4640121, Oldrini Edoardo 4055097***\n",
    "\n",
    "**Abstract**\n",
    "\n",
    "The following data analysis aims to study an approach for the production of a movie.<br><br>\n",
    "This file is divided like so:\n",
    "* Dataset checking and preparation\n",
    "* Initial exploration of the dataset\n",
    "* Raising hypotheses and subsequent verification\n",
    "* Proposal for a predictive regression based on previous observations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing libraries and datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.17.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # used for plot interactive graph.\n",
    "import numpy as np \n",
    "import plotly.offline as py\n",
    "import json\n",
    "from plotnine import ggplot,aes,facet_grid,labs,geom_col,theme_xkcd\n",
    "py.init_notebook_mode(connected=True) #TODO ????\n",
    "import plotly.graph_objs as go\n",
    "import warnings #TODO ????\n",
    "warnings.filterwarnings('ignore') #TODO ????\n",
    "from pylab import rcParams #TODO ????\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies = pd.read_csv('tmdb_5000_movies.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploratory analysis of the dataset**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving all columns with Json data into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(x):\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        return names\n",
    "    return []\n",
    "\n",
    "def get_ISO(x):\n",
    "    if isinstance(x, list):\n",
    "        isos = [i['iso_3166_1'] for i in x]\n",
    "        return isos\n",
    "    return []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzioni per passare da json a liste dei dati utili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_to_manage = ['genres','keywords','production_countries','production_companies'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in feat_to_manage:\n",
    "    Movies[f] = Movies[f].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn genres into list\n",
    "Movies['genres'] = Movies['genres'].apply(get_name)\n",
    "#Turn prod_countries into list\n",
    "Movies['production_countries'] = Movies['production_countries'].apply(get_ISO)\n",
    "#Turn prod_companies into list\n",
    "Movies['production_companies'] = Movies['production_companies'].apply(get_name)\n",
    "#Turn keywords into list\n",
    "Movies['keywords'] = Movies['keywords'].apply(get_name)\n",
    "\n",
    "Movies.head(1)\n",
    "\n",
    "print(\"Generi hanno tipo \", type(Movies['genres'][0]))\n",
    "print(\"Paesi produzione hanno tipo \", type(Movies['production_countries'][0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dataset dimension and an overview of the table itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 4803 rows and 17 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset has {} rows and {} columns\".format(Movies.shape[0],Movies.shape[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Droppiamo colonne inutili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies.drop(['homepage','spoken_languages','original_title'],inplace=True,axis='columns')\n",
    "Movies.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Controlliamo chei tipi siano giusti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tipi sono coerenti"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Controlliamo se ci sono dati mancanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Movies.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ci sono alcuni valori nulli ma in colonne che potrebbero non essere significative"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Controlliamo che i budget abbiano valori sensati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO possibile predizione buget come studio\n",
    "print(Movies['budget'].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il valore minimo è 0, abbiamo quindi il dubbbio che ci siano budget con valori insiensati, per conoscenza del dominio applciativo decidiamo di porre il limite inferiore di 10k per il budget, verifichiamo quanti film sono sotto a questo valore."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci sono 1400 film con un valore di budget che non sembra avere senso, per evitare di eliminare tutti i dati relativi a questo film decidiamo di \"segnarli\" ponendo il budget ad un valore simbolico di -1 questi dati in modo da non prenderli in considerazione nelle statistiche ma non perdere altri dati interesanti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Movies[Movies['budget'] <= 10000]['budget'] = np.nan\n",
    "for row in Movies.index:\n",
    "    if Movies.loc[row,'budget'] < 10000 and (Movies.loc[row, 'status']=='Released'):\n",
    "        Movies.loc[row,'budget'] = np.nan\n",
    "print(Movies[Movies['budget'] == np.nan].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Movies[Movies['budget']<10000]['id'].count())\n",
    "#Movies.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Controlliamo che i revenue abbiano valori sensati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO possibile predizione buget come studio\n",
    "#Movies.tail()\n",
    "print(Movies['revenue'].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "molti film hanno revenue nullo, che siano film ancora non usciti?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Movies with 0$ revenues: ',Movies[Movies['revenue'] == 0].shape[0])\n",
    "print('Movies not yet released', Movies[(Movies['revenue'] == 0) & (Movies['status']!= 'Released')].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Su 1427 film che hanno revenue = 0 solo 7 sono ancora in fase di produzione, quindi 1427 film hanno un valore di revenue errato che procediamo a segnare, come visto precedentemente, con un valore simbolico di -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in Movies.index:\n",
    "    if (Movies.loc[row, 'revenue'] == 0) and (Movies.loc[row, 'status']=='Released'):\n",
    "        Movies.loc[row, 'revenue'] = -1\n",
    "\n",
    "print('Movies without revenue infos: ',Movies[Movies['revenue'] == -1].shape[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Ulteriori aggiustamenti"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiungiamo due colonne legate al budget, una misura i ricavi sulla percentuale rispetto al budget, l'altra divide i film in 3 categorie, low budget, normali e blockbuster\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Ricavi rispetto al budget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_profit_perc(x):\n",
    "    if (x.revenue>0) and (x.budget>0):\n",
    "        return ((x.revenue-x.budget)/x.budget)*100\n",
    "    #senza else mette i nan, altrimenti possiamo metterlo e ritornare -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Movies = Movies.assign(profit_perc = lambda x: (((x.revenue-x.budget)/x.budget)*100) if ((x.revenue>0) and (x.budget>0)) else -1)\n",
    "#print(Movies[Movies['budget'].isnull()])\n",
    "Movies = Movies.assign(profit_perc = lambda x: x.budget)\n",
    "for row in Movies.index:\n",
    "    Movies.loc[row,'profit_perc'] =  calculate_profit_perc(Movies.loc[row])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Classificazioni film in low, med, high budget"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usiamo describe per capire come impostare gli scaglioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies[Movies['budget']>0]['budget'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low budget = 25% con budget più bassi<br>\n",
    "High budget = 25% con budget più alti<br>\n",
    "Medio = il restante 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def budget_range(x):\n",
    "    if x <= 0: #x==NaN\n",
    "        return \"no budget info\"\n",
    "    if x < 7.900000e+05:\n",
    "        return \"low\"\n",
    "    elif x >= 7.900000e+05 and x < 4.000000e+07:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aggiungiamo una colonna che contiene l'etichetta relativa al budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies = Movies.assign(budget_class = lambda x: str(x.budget))\n",
    "for row in Movies.index:\n",
    "    Movies.loc[row,'budget_class'] =  budget_range(Movies.loc[row,'budget'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: perchè prendiamo solo i budget>10^7 e non tutti i non negativi?\n",
    "#sns.kdeplot(data=Movies[Movies['budget'] >0], x='budget', shade = True)\n",
    "sns.kdeplot(data=Movies[Movies['budget'] >= 4.000000e+07], x='budget', shade = True)\n",
    "plt.legend(['Budget'])\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riteniamo importante che la media dei voti sia pesata con il numero di voti che la generano, per fare questo usiamo una formula consigliata dal celebre sito IMBD e togliamo le due colonne average e count per unirle in una che le metta insieme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: potremmo anche fare questo lavoro sul dataset di partenza aggiungendo una colonna, metà avranno nan\n",
    "C= Movies['vote_average'].mean()\n",
    "C\n",
    "m= Movies['vote_count'].quantile(0.5)\n",
    "\n",
    "for i in Movies.index:\n",
    "    if Movies.loc[i,'vote_count'] <= m:\n",
    "        Movies.loc[i,'vote_count'] = np.nan\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "q_movies = Movies[['id','vote_count','vote_average']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = x['vote_count']\n",
    "    R = x['vote_average']\n",
    "    # Calculation based on the IMDB formula\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new feature 'score' and calculate its value with `weighted_rating()`\n",
    "q_movies['score'] = q_movies.apply(weighted_rating, axis=1)\n",
    "q_movies.drop(['vote_average','vote_count'],inplace=True,axis='columns')\n",
    "#Merge dei dataframe,ora Movies ha anche la colonna Score\",\n",
    "Movies = pd.merge(Movies,q_movies,on='id',how='inner')\n",
    "Movies.shape\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo eliminato metà dei film, quelli con troppi pochi voti per poter essere presi in considerazione per quanto riguarda il voto ricevuto."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breve sguardo agli attributi quantitativi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cominciamo a fare qualche ipotesi**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Dati qualitativi**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usiamo una funziona di libreria per portare genri, keyword, paesi di produzione e compagnie di produzione in un formato più semplice da gestire"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************************************************************************************************************************\n",
    "******************************************************************************************************************************************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dati qualitativi ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proviamo a definire delle funzioni per verificare la distribuzione di voti e soldoni fatti in base ai dati qualitativi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: perchè è commentata? Non serve più?\n",
    "#def get_name(x):\n",
    " #   if isinstance(x, list):\n",
    "  #      names = [i['name'] for i in x]\n",
    "   #     return names\n",
    "    #return []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primo qualitativo: generi ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. definiamo funzione che dato un genere calcola la media dei profitti dei film che lo contengono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_average_profits(genre):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for row in Movies.index:\n",
    "        if (genre in Movies.loc[row, 'genres']) and (Movies.loc[row,'profit_perc'] > 0):\n",
    "            sum += Movies.loc[row, 'profit_perc']\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "#Movies['profit_perc'] = Movies.apply(lambda row: genre_average_profits(row['genres']), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. estraiamo dal dataset la lista dei generi presenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I generi presenti nel dataframe sono:\n",
      "\t [\n",
      "\t {\n",
      "\t \"\n",
      "\t i\n",
      "\t d\n",
      "\t :\n",
      "\t  \n",
      "\t 2\n",
      "\t 8\n",
      "\t ,\n",
      "\t n\n",
      "\t a\n",
      "\t m\n",
      "\t e\n",
      "\t A\n",
      "\t c\n",
      "\t t\n",
      "\t o\n",
      "\t }\n",
      "\t 1\n",
      "\t v\n",
      "\t u\n",
      "\t r\n",
      "\t 4\n",
      "\t F\n",
      "\t s\n",
      "\t y\n",
      "\t 7\n",
      "\t S\n",
      "\t ]\n",
      "\t 0\n",
      "\t C\n",
      "\t D\n",
      "\t 5\n",
      "\t 3\n",
      "\t T\n",
      "\t h\n",
      "\t l\n",
      "\t 6\n",
      "\t W\n",
      "\t 9\n",
      "\t R\n",
      "\t H\n",
      "\t M\n",
      "\t g\n",
      "\t V\n"
     ]
    }
   ],
   "source": [
    "genres=[]\n",
    "for row in Movies.index:\n",
    "    _gen = Movies.loc[row,'genres']\n",
    "    for g in _gen:\n",
    "        if g not in genres:\n",
    "            genres.append(g)\n",
    "\n",
    "print(\"I generi presenti nel dataframe sono:\")\n",
    "for el in genres:\n",
    "    print('\\t',el)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. calcoliamo e salviamo il profitto medio di ogni genere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'profit_perc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'profit_perc'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m profits\u001b[39m=\u001b[39m[]\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m genres:\n\u001b[0;32m----> 3\u001b[0m     profits\u001b[39m.\u001b[39mappend(genre_average_profits(g))\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mProfitto associato ad ogni genere:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(genres)):\n",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m, in \u001b[0;36mgenre_average_profits\u001b[0;34m(genre)\u001b[0m\n\u001b[1;32m      3\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m Movies\u001b[39m.\u001b[39mindex:\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mif\u001b[39;00m (genre \u001b[39min\u001b[39;00m Movies\u001b[39m.\u001b[39mloc[row, \u001b[39m'\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mand\u001b[39;00m (Movies\u001b[39m.\u001b[39;49mloc[row,\u001b[39m'\u001b[39;49m\u001b[39mprofit_perc\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m      6\u001b[0m         \u001b[39msum\u001b[39m \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m Movies\u001b[39m.\u001b[39mloc[row, \u001b[39m'\u001b[39m\u001b[39mprofit_perc\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m         count\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1066\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1064\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(com\u001b[39m.\u001b[39mapply_if_callable(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n\u001b[1;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_get_value(\u001b[39m*\u001b[39;49mkey, takeable\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_takeable)\n\u001b[1;32m   1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3914\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   3911\u001b[0m     series \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ixs(col, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m   3912\u001b[0m     \u001b[39mreturn\u001b[39;00m series\u001b[39m.\u001b[39m_values[index]\n\u001b[0;32m-> 3914\u001b[0m series \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_item_cache(col)\n\u001b[1;32m   3915\u001b[0m engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_engine\n\u001b[1;32m   3917\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   3918\u001b[0m     \u001b[39m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   3919\u001b[0m     \u001b[39m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   3920\u001b[0m     \u001b[39m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4271\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4266\u001b[0m res \u001b[39m=\u001b[39m cache\u001b[39m.\u001b[39mget(item)\n\u001b[1;32m   4267\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4268\u001b[0m     \u001b[39m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[1;32m   4269\u001b[0m     \u001b[39m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[0;32m-> 4271\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(item)\n\u001b[1;32m   4272\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ixs(loc, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m   4274\u001b[0m     cache[item] \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'profit_perc'"
     ]
    }
   ],
   "source": [
    "profits=[]\n",
    "for g in genres:\n",
    "    profits.append(genre_average_profits(g))\n",
    "            \n",
    "print(\"Profitto associato ad ogni genere:\")\n",
    "for i in range(0,len(genres)):\n",
    "    print('\\t',genres[i], \" has a mean profit of \", profits[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due generi hanno una media pari a 0, appaiano quindi solo nei film per cui non abbiamo info su budget e/o revenue, li eliminiamo quindi dalla lista dei generi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres.remove(genres[19])\n",
    "genres.remove(genres[18])\n",
    "profits.remove(profits[19])\n",
    "profits.remove(profits[18])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Di seguito possiamo vedere come sono i profitti in base ai diversi generi dei film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: riusciamo a farli in ordine decrescente sul grafico?\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(genres,profits)\n",
    "fig.set_figwidth(27)\n",
    "fig.set_figheight(13)\n",
    "plt.xticks(rotation=45,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Genres\", fontsize=20)\n",
    "plt.ylabel(\"Profits\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ottimizzare le funzioni di libreria sostituiamo ai valori dei profitti associati ai film con dati insufficienti a calcolarli il valore nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: si può mica fare da subito?\n",
    "for row in Movies.index:\n",
    "    if (Movies.loc[row, 'profit_perc'] <= 0) and (Movies.loc[row, 'status']=='Released'):\n",
    "        Movies.loc[row, 'profit_perc'] = np.nan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondo qualitativo: keywords ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. importiamo i profitti e le keywords associate solo a film su cui non abbiamo dati relativi ai profitti, precedentemente calcolate con una funzione pesante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key_profits = pd.read_csv('key_profits.csv')['0']\n",
    "#bad_key_df = pd.read_csv('bad_key.csv')\n",
    "#bad_key=bad_key_df['0']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. estraiamo dal dataset la lista delle presenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords=[]\n",
    "for row in Movies.index:\n",
    "    _key = Movies.loc[row,'keywords']\n",
    "    for k in _key:\n",
    "        if g not in keywords:\n",
    "            keywords.append(k)\n",
    "print(len(keywords))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. definiamo una funzione che data una keyword ne calcola la media dei profitti associati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_average_profit(keywords):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for row in Movies.index:\n",
    "        if (keywords in Movies.loc[row, 'keywords'] and Movies.loc[row, 'profit_perc'] >= 0):\n",
    "            sum += Movies.loc[row, 'profit_perc']\n",
    "            count+=1\n",
    "    if count != 0:\n",
    "        return sum/count\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ora per ogni keyword calcoliamo il profitto e salviamo quali keywords non hanno dati su budget o revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione pesantissima con hash\n",
    "set_key = set(keywords)\n",
    "key_profits={} #declared as hashmap\n",
    "bad_keys=[]\n",
    "for k in set_key:\n",
    "    q = keyword_average_profit(k)\n",
    "    if q != -1:\n",
    "        key_profits[str(k)]=q\n",
    "    else:\n",
    "        bad_keys.append(k)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. A questo punto castiamo l'array di tutte le keywords e di quelle da scartare in set, così da eleminare ogni duplicato e poter effettuare una differenza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_key_set = set(bad_keys)\n",
    "set_key_cleaned = set_key - bad_key_set\n",
    "\n",
    "print(\"Numero di keywords:\\t\",len(set_key))\n",
    "print(\"Numero di keywords da scartare\\t\",len(bad_key_set))\n",
    "print(\"Numero di keywords da analizzare:\\t\",len(set_key_cleaned))\n",
    "print(\"Numero di profitti per le keywords calcolati\\t\",len(key_profits))\n",
    "\n",
    "#pd.DataFrame(key_profits).to_csv(\"key_profits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_key_hash = sorted(key_profits.items(), key=lambda x: x[1])\n",
    "print(sorted_key_hash)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. visto il grande numero di keywords presenti nel dataset ci concentriamo su quelle più presenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter #per prendere le più presenti\n",
    "\n",
    "best = 100 #numero di keywords da studiare \n",
    "_most_common_keys = Counter(keywords).most_common(best)\n",
    "most_common_keys = []\n",
    "for i in range(0,best-1):\n",
    "    #print(most_common_keys[0])\n",
    "    most_common_keys.append(_most_common_keys[i][0])\n",
    "print(most_common_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#associamo alle key più frequenti selezionate sopra il rispettivo profitto\n",
    "most_common_keys_prof = []\n",
    "for el in most_common_keys:\n",
    "    most_common_keys_prof.append(key_profits[str(el)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. stampiamo ora un istogramma che associa alle keywords più comuni il rispettivo profitto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(most_common_keys,most_common_keys_prof)\n",
    "fig.set_figwidth(27)\n",
    "fig.set_figheight(13)\n",
    "plt.xticks(rotation=90,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"key\", fontsize=20)\n",
    "plt.ylabel(\"Profits\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visto che il grafico così è poco leggibile rappresentiamo i risutlati in un altro modo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(12,12))\n",
    "stop_words=set(stopwords.words('english'))\n",
    "stop_words.update(',',';','!','?','.','(',')','$','#','+',':','...',' ','')\n",
    "\n",
    "Movies['keywords'].dropna(inplace=True)\n",
    "Movies['keywords'] = Movies['keywords'].astype(str)\n",
    "words=Movies['keywords'].apply(nltk.word_tokenize)\n",
    "word=[]\n",
    "for i in words:\n",
    "    word.extend(i)\n",
    "word=pd.Series(word)\n",
    "word=([i for i in word.str.lower() if i not in stop_words])\n",
    "wc = WordCloud(background_color=\"black\", max_words=4000,stopwords=STOPWORDS, max_font_size= 60,width=1000,height=1000)\n",
    "wc.generate(\" \".join(word))\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(10,10)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "si può fare altro, ma ora ci spostiamo su altro..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qualitiativo 3: paesi di produzione ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Troviamo e salviamo tutti i paesi di produzione del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries=[]\n",
    "for row in Movies.index:\n",
    "    _countries = Movies.loc[row,'production_countries']\n",
    "    for k in _countries:\n",
    "        if k not in countries:\n",
    "            countries.append(k)\n",
    "\n",
    "print(len(countries))\n",
    "print(countries)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. definiamo una funzione che dato un pease di produzine calcoli il profitto dei film girati li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_average_profit(country):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for row in Movies.index:\n",
    "        if (country in Movies.loc[row, 'production_countries'] and Movies.loc[row, 'profit_perc'] >= 0):\n",
    "            sum += Movies.loc[row, 'profit_perc']\n",
    "            count+=1\n",
    "    if count != 0:\n",
    "        return sum/count\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. creiamo una hashmap in cui associamo ad ogni paese di produzione il relativo profitto, mettendo in bad_countries i paesi i cui film non hanno info sufficienti per il calcolo dei profitti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_profits={} #declared as hashmap\n",
    "bad_countries=[] #TODO: si può fare subito set o serve array?\n",
    "for c in countries:\n",
    "    q = country_average_profit(c)\n",
    "    if q != -1:\n",
    "        country_profits[str(c)]=q\n",
    "    else:\n",
    "        bad_countries.append(c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. rimuoviamo i paesi di produzione dei cui film non abbiamo info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_countries = set(countries)\n",
    "bad_countries_set = set(bad_countries)\n",
    "set_countries_cleaned = set_countries - bad_countries_set\n",
    "\n",
    "\n",
    "print(\"Numero di paesi di produzione totali:\\t\\t\",len(set_countries))\n",
    "print(\"Numero di paesi di produzione da scartare:\\t\",len(bad_countries_set))\n",
    "print(\"Numero di paesi di produzione da analizzare:\\t\",len(set_countries_cleaned))\n",
    "print(\"Numero di profit per paese da analizzare:\\t\",len(country_profits))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. mettiamo in un array, nel giusto ordine, i profitti da plottare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_profits_plot = []\n",
    "for el in set_countries_cleaned:\n",
    "    country_profits_plot.append(country_profits[str(el)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(list(set_countries_cleaned),list(country_profits_plot))\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(13)\n",
    "plt.xticks(rotation=90,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"key\", fontsize=20)\n",
    "plt.ylabel(\"Profits\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Notiamo un valore molto alto per la Jamaica, ci stupisce. Controlliamo quanti e quali film ci sono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in Movies.index:\n",
    "    if 'JM' in Movies.loc[row,'production_countries']:\n",
    "        print(Movies.loc[row,'profit_perc'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solo due, dobbiamo fare lo stesso lavoro fatto per le keywords sulla frequenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: fare country con frequenza"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************************************************************************************************************************\n",
    "******************************************************************************************************************************************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logaritmi, decidere dove va fatto!!##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "purtroppo la distrubuzione dei profitti è pessima e potrebbe portare a delle rpoblematiche future, per migliorarla possiamo applicare la funzione logaritmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: separare in due fasi, prima stampiamo la distribuzione, poi diciamo che fa cagare e dopo applichiamo log e diciamo che va meglio\n",
    "Movies['log_perc'] = np.log(Movies['profit_perc'])\n",
    "fig, ax = plt.subplots(figsize = (16, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(Movies['profit_perc'])\n",
    "plt.title('Distribution of Profits%')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(Movies['log_perc'])\n",
    "plt.title('Log Distribution of Profits%')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il grafico sembra dire che il log ha funzionato, controliamo la skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Skewness : %f '% Movies['profit_perc'].skew())\n",
    "print('Applied Log Skewness : %f '% Movies['log_perc'].skew())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i risutlati confermano quanto suggerito dal grafico, analizziamo ancora come la distribuzione sia cambiata e quanto effettivamente sia migliorata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(Movies['profit_perc'])\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.legend(['Profit'])\n",
    "plt.title('Profit Perc')\n",
    "sns.distplot(Movies['log_perc'])\n",
    "plt.legend(['Profit'])\n",
    "plt.title('Log Profit Perc')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "miglioratissima....ossia studiamo bene cosa vogliono dire sti grafici"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************************************************************************************************************************\n",
    "******************************************************************************************************************************************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset unito a crew ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iniziamo a lavorare con il dataset contenente il cast e il direttore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast = pd.read_csv(\"tmdb_5000_credits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_to_manage = ['cast','crew']\n",
    "for f in feat_to_manage:\n",
    "    cast[f] = cast[f].apply(literal_eval)\n",
    "\n",
    "#Two functions that convert directors and actors from json to list-str\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "\n",
    "def get_actors(x): #TODO:si può usare senza fare modifiche get_name?\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        \n",
    "        return names\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two new column correctly formatted\n",
    "cast['director'] = cast['crew'].apply(get_director)\n",
    "cast['actors'] = cast['cast'].apply(get_actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop old columns\n",
    "cast.drop('cast',inplace=True,axis=1)\n",
    "cast.drop('crew',inplace=True,axis=1)\n",
    "cast.drop('title',inplace=True,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename Movie_id to id, preparing for the merge\n",
    "cast = cast.rename(columns={'movie_id': 'id'})\n",
    "\n",
    "#Merge two dataframe Movies,cast\n",
    "full_df = pd.merge(Movies,cast,on=\"id\",how=\"inner\")\n",
    "#full_df.to_csv(\"updated.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many times actors appears in different films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "actors=[]\n",
    "\n",
    "\n",
    "for i in full_df['actors']:\n",
    "    actors.extend(i)\n",
    "\n",
    "actors = list(filter(None, actors))\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(12,10))\n",
    "ax=pd.Series(actors).value_counts()[:15].sort_values(ascending=True).plot.barh(width=0.9,color=sns.color_palette('inferno_r',40))\n",
    "for i, v in enumerate(pd.Series(actors).value_counts()[:15].sort_values(ascending=True).values): \n",
    "    ax.text(.8, i, v,fontsize=10,color='white',weight='bold')\n",
    "\n",
    "plt.title('Actors with highest appearance')\n",
    "ax.patches[14].set_facecolor('r')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registi ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors=[]\n",
    "\n",
    "\n",
    "for i in full_df['director']:\n",
    "    directors.append(i)\n",
    "\n",
    "directors = list(filter(None, directors))\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(12,10))\n",
    "ax=pd.Series(directors).value_counts()[:34].sort_values(ascending=True).plot.barh(width=0.9,color=sns.color_palette('inferno_r',40))\n",
    "for i, v in enumerate(pd.Series(directors).value_counts()[:34].sort_values(ascending=True).values): \n",
    "    ax.text(.8, i, v,fontsize=10,color='white',weight='bold')\n",
    "\n",
    "plt.title('Directors with highest appearance')\n",
    "ax.patches[14].set_facecolor('r')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo Score medio per i registi più presenti(>= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the directors with made films >= 10,then calculate the mean scores\n",
    "#Dovrebbe fare lo stesso lavoro di score_for_director applicato poi alla hashmap, quindi ho rimosso entrambe\n",
    "\n",
    "director_group = full_df.groupby('director').filter(lambda x : len(x) >= 10)\n",
    "mean_scores = director_group.groupby('director')['score'].mean().sort_values(ascending=False).reset_index(name=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(mean_scores['director'],mean_scores['score'])\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(13)\n",
    "plt.xticks(rotation=90,fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Directors\", fontsize=20)\n",
    "plt.ylabel(\"Scores\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cerchiamo non rating ma score: Fatto ^"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************************************************************************************************************************\n",
    "******************************************************************************************************************************************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dati quantitativi ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prendiamo solo il primo valore dei quantitativi \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Get only the first genre of each films,\n",
    "full_df['genres'] = full_df.apply(lambda x: x['genres'][0] if len(x['genres'])>0 else None, axis=1)\n",
    "#attori\n",
    "full_df['actors'] = full_df.apply(lambda x: x['actors'][0] if len(x['actors'])>0 else None, axis=1)\n",
    "#keywords\n",
    "full_df['keywords'] = full_df.apply(lambda x: x['keywords'][0] if len(x['keywords'])>0 else None, axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************************************************************************************************************************\n",
    "******************************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "full_df['director'] = encoder.fit_transform(full_df['director'])\n",
    "full_df['genres'] = encoder.fit_transform(full_df['genres'])\n",
    "full_df['actors'] = encoder.fit_transform(full_df['actors'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vogliamo predire la budget_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_df.loc[full_df['score'].isna()]\n",
    "full_df = full_df.dropna(subset=['score'])#poi provare a sostituire nulli con media\n",
    "full_df.dropna(subset=['profit_perc'],inplace=True)\n",
    "\n",
    "#print(full_df['score'].tail)\n",
    "#print(full_df.isnull().sum())\n",
    "#full_df.query('keywords == \"None\"')\n",
    "#print(full_df[len(full_df['keywords']) != 0].count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mappiamo in binario le qualitative che vogliamo usare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genere\n",
    "one_hot = OneHotEncoder()\n",
    "gen_encoded = one_hot.fit_transform(full_df[['genres']])\n",
    "full_df[one_hot.categories_[0]] = gen_encoded.toarray()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_drop = ['actors','id','genres','vote_average','vote_count','keywords','overview','production_companies','production_countries','original_language','release_date','status','tagline','title','director']\n",
    "full_df = full_df.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profit_range(x):\n",
    "    if x <= 0: #x==NaN\n",
    "        return \"money loss\"\n",
    "    if x < 1.088395e+02:\n",
    "        return \"low_profit\"\n",
    "    elif x >= 1.088395e+02 and x < 2.308242e+02:\n",
    "        return \"medium_profit\"\n",
    "    elif x >= 2.308242e+02 and x < 4.784476e+02:\n",
    "        return \"high_profit\"\n",
    "    else:\n",
    "        return \"Big Money\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_encoded = one_hot.fit_transform(full_df[['profit_class']])\n",
    "full_df[one_hot.categories_[0]] = budget_encoded.toarray()\n",
    "#full_df.drop('budget_class',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = full_df.assign(profit_class = lambda x: str(x.profit_perc))\n",
    "for row in full_df.index:\n",
    "    full_df.loc[row,'profit_class'] =  profit_range(full_df.loc[row,'profit_perc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_df.drop('budget_class',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = full_df.pop('profit_class')\n",
    "full_df.insert(0,'profit_class',fc)\n",
    "#full_df = full_df.iloc[: ,-3]\n",
    "full_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df.iloc[:, 1:]\n",
    "y = full_df['profit_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,test_size=0.3,random_state=100)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a model and making predictions\n",
    "forest.fit(X_train,y_train)\n",
    "predictions = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy : \",metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "fig = plt.figure(figsize=(150,100))\n",
    "plot_tree(forest.estimators_[0],feature_names=X.columns,class_names=full_df['profit_class'].unique(),filled=True,rounded=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non sapevo come fare con le foreste, sono andato con le similarità tra film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "full_df['overview'] = full_df['overview'].fillna('')\n",
    "tfidf_matr = tfidf.fit_transform(full_df['overview'])\n",
    "print(tfidf_matr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_similarity = linear_kernel(tfidf_matr,tfidf_matr)\n",
    "cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(full_df.index, index=full_df['title']).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_df.query('title == \"The Sting\"')['overview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommendation using cosine similarity\n",
    "def get_recommendations(title, cosine_similarity=cosine_similarity):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwise similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_similarity[idx]))\n",
    "    #print(sim_scores)\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    #print(sim_scores)\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return full_df['title'].iloc[movie_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2731     The Godfather: Part II\n",
       "1873                 Blood Ties\n",
       "867     The Godfather: Part III\n",
       "3727                 Easy Money\n",
       "3623                       Made\n",
       "3125                     Eulogy\n",
       "3896                   Sinister\n",
       "4506            The Maid's Room\n",
       "3783                        Joe\n",
       "2244      The Cold Light of Day\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Godfather')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommendations using keyword,actors and director**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer and create the count matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Compute the Cosine Similarity matrix based on the count_matrix\n",
    "#from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        #Check if director exists. If not, return empty string\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply clean_data function to your features.\n",
    "features = ['actors', 'keywords', 'director', 'genres']\n",
    "\n",
    "for feature in features:\n",
    "    full_df[feature] = full_df[feature].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(x):\n",
    "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['actors']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n",
    "full_df['soup'] = full_df.apply(create_soup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(full_df['soup'])\n",
    "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)\n",
    "# Reset index of our main DataFrame and construct reverse mapping as before\n",
    "full_df = full_df.reset_index()\n",
    "indices = pd.Series(full_df.index, index=full_df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2731      The Godfather: Part II\n",
       "867      The Godfather: Part III\n",
       "4638    Amidst the Devil's Wings\n",
       "4209            The Conversation\n",
       "3293                 10th & Wolf\n",
       "2255                   The Yards\n",
       "1394               Donnie Brasco\n",
       "3012               The Outsiders\n",
       "4124          This Thing of Ours\n",
       "1018             The Cotton Club\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(\"The Godfather\", cosine_sim2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "droppare i nan\n",
    "mettere in codifica hot il primo elemento delle colonne colonne:\n",
    "    genere\n",
    "    keyword\n",
    "    director\n",
    "    attori\n",
    "    paese produ\n",
    "    \n",
    "_____________________________________________________________________\n",
    "fare random forest che predice score/popul/rev/profit/altro usando le colonne fatte sopra\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************************************************************************************************************************\n",
    "******************************************************************************************************************************************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TOTO: \n",
    "\n",
    "Toccherà caccaire nel cesso le hashmap\n",
    "\n",
    "non è che tocca lavorare sui profitti ottenuti col logaritmo?\n",
    "\n",
    "trovare modo per selezionare solo le country utili (con abbastanza film)\n",
    "\n",
    "#mettere al posto dei -1 i NaN ma solo nella singola colonna non su tutta la riga\n",
    " \n",
    "Qualitativi --> plot e contare, no correlazioni\n",
    "\n",
    "sarebbe carino trovare sia le key con più profitto tra le più comuni sia le più comuni tra quelle con più profitto\n",
    "\n",
    "#Eliminare valori inutile e insensati anche per revenue e \"segnarli\"\n",
    "#Ricalcolare profit selezinando solo i film con valori sensati (!=-1)\n",
    "\n",
    "Plottare profitto in base a:\n",
    "    #genere\n",
    "    keyword\n",
    "    paese prod\n",
    "    lingua originale (forse)\n",
    "\n",
    "Plottare count dei generi in per ogni paese di prod (ad esempio giappone potrebbe avere più animazione della GB)\n",
    "\n",
    "\\************************************************\n",
    "\n",
    "Dati quantitativi --> matematica:\n",
    "\n",
    "Provare corr tra profitto(non revenue) e budget \n",
    "Provare corr tra profitto(non revenue) e score \n",
    "Provare corr tra profitto(non revenue) e popularity \n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "usiamo tutte le verità scoperte per fare varie predizioni\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
